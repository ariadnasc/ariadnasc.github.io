<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ariadna's Profile</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div id="branding">
                <h1>Ariadna Sanchez</h1>
                <p>Doctoral Student at the Centre for Doctoral Training in NLP at the University of Edinburgh</p>
            </div>
            <nav>
                <ul>
                    <li><a href="#about">About</a></li>
                    <li><a href="#research">Research</a></li>
                    <li><a href="#career">Career</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <li><a href="#conferences">Conferences</a></li>
                    <li><a href="#media">Media</a></li>
                    <li><a href="#other">Other</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <div class="container main-content">
        <section id="about">
            <h2>About Me</h2>
            <img src="IMG_1840.jpeg" alt="Ariadna Sanchez">
            <ul>
                <li>Currently completing a PhD at the University of Edinburgh in personalised speech synthesis for atypical voices. I am also part of the CSTR and ILCC departments.</li>
                <li>Lecturer in NLP and speech technologies at the Universitat Politècnica de Catalunya, at the Postgraduate Course in Deep Learning program (both online and in person).</li>
                <li>Tutor in speech technology courses at the University of Edinburgh (Automatic Speech Recognition, Speech Processing and Speech Synthesis).</li>
                <li>Part of the committee at <a href="https://youngitgirls.org/ca/apropem-la-tecnologia-a-estudiants/">Young IT Girls</a>, and in charge of the activities team.</li>
            </ul>
        </section>

        <section id="research">
            <h2>Research Interests</h2>
            <p>I am interested in speech technologies, natural language processing, acoustics and language acquisition.</p>
            <p>In particular, I focus on personalised speech synthesis for atypical voices, TTS evaluation and the intersectionality between gender and speech technologies.</p>
            <p>I am very open to collaborations, don't hesitate to reach out!</p>
        </section>

        <section id="career">
            <h2>Career</h2>
            <ul>
                <li>2023-present: PhD researcher at the Centre for Doctoral Training in NLP at the University of Edinburgh (Scotland). Member of the Centre for Speech Technology Research (CSTR).</li>
                <li>2019-2023: TTS Research Scientist at Amazon (Cambridge, England, and Edinburgh, Scotland).</li>
                <li>2018-2019: TTS Language Engineer Intern at Amazon (Gdańsk, Poland).</li>
                <li>2017-2018: MSc Speech and Language Processing with Distinction at the University of Edinburgh (Scotland).</li>
                <li>2017: BSc dissertation conducted as an Erasmus student at the University of Limerick (Ireland).</li>
                <li>2013-2017: BSc Audiovisual Systems Engineering at Universitat Politecnica de Catalunya (Barcelona).</li>
            </ul>
        </section>

        <section id="publications">
            <h2>Publications</h2>
            <ul>
                <li><b><i>Sanchez, A.</i></b>, Ross, A., Markl, N. (2024) Beyond the Binary: Limitations and Possibilities of Gender-related Speech Technology Research. Proc. IEEE Spoken Language Technology (SLT) Workshop 2024.</li>
                <li><b><i>Sanchez, A.</i></b>, Falai, A., Zhang, Z., Angelini, O., Yanagisawa, K. (2022) Unify and Conquer: How Phonetic Feature Representation Affects Polyglot Text-To-Speech (TTS). Proc. Interspeech 2022, 2963-2967, doi: 10.21437/Interspeech.2022-233. <a href="https://www.isca-archive.org/interspeech_2022/sanchez22_interspeech.html">Link to paper.</a></li>
                <li>Zhang, Z., Falai, A., <b><i>Sanchez, A.</i></b>, Angelini, O., Yanagisawa, K. (2022) Mix and Match: An Empirical Study on Training Corpus Composition for Polyglot Text-To-Speech (TTS). Proc. Interspeech 2022, 2353-2357, doi: 10.21437/Interspeech.2022-242. <a href="https://www.isca-archive.org/interspeech_2022/zhang22c_interspeech.html">Link to paper.</a></li>
                <li>Deja, K., <b><i>Sanchez, A.</i></b>, Roth, J., Cotescu, M. (2022) Automatic Evaluation of Speaker Similarity. Proc. Interspeech 2022, 2348-2352, doi: 10.21437/Interspeech.2022-75. <a href="https://www.isca-archive.org/interspeech_2022/deja22_interspeech.html">Link to paper.</a></li>
                <li>Luque, J., Segura, C., <b><i>Sanchez, A.</i></b>, Umbert, M., & Galindo, L. A. (2017). The Role of Linguistic and Prosodic Cues on the Prediction of Self-Reported Satisfaction in Contact Centre Phone Calls. In INTERSPEECH (pp. 2346-2350). <a href="https://www.isca-archive.org/interspeech_2017/luque17_interspeech.html">Link to paper.</a></li>
                <li><b><i>Sanchez, A.</i></b> (2017). Effects of room acoustics on players' perceptions in audio games (Bachelor's thesis, Universitat Politècnica de Catalunya). <a href="https://upcommons.upc.edu/handle/2117/106702">Link to thesis.</a></li>
            </ul>
        </section>

        <section id="conferences">
            <h2>Conferences, Talks and Poster Sessions</h2>
            <ul>
                <li><b><i>Sanchez, A.</i></b>, Jones, J., Verdugo, J. (2024) To listen or not to listen? A quasi-experimental study on reading-only versus reading-while-listening for incidental vocabulary learning in L2 Spanish learners at different levels of lexical proficiency. British Association for Applied Linguistics Conference 2024 (Essex, UK). 
                <li><b><i>Sanchez, A.</i></b>, King, S. (2024) Self-supervised models for dysarthric speech: Understanding representations through visual analysis and probing. UK and Ireland Speech Workshop 2024, Cambridge. <a href="https://ukis2024.eng.cam.ac.uk/wp-content/uploads/2024/07/ukis2024-AbstractBook.pdf">Link to abstract (page 47)</a>.</li>
                <li>2022-2023 - Guest lecture on TTS research at Alexa at the Postgraduate Course in Deep Learning at the Universitat Politecnica de Catalunya.</li>
                <li>2018-2023 - Various talks on TTS research at Alexa at Universitat Politecnica de Catalunya (Barcelona), University of Edinburgh, Imperial College London, and Universidad de Costa Rica.</li>
            </ul>
        </section>

        <section id="media">
            <h2>Other media</h2>
            <ul>
                <li>2024 - Opinion article written by me (in catalan) about the use of AI in everyday life. <a href="https://www.metadata.cat/opinio/4741/fem-us-ia-consciencia-ariadna-sanchez-yitg">Link.</a></li>
                <li>2022 - Interview about my research and career at Amazon Alexa and prior. <a href="https://www.amazon.science/working-at-amazon/how-a-lifelong-music-student-uses-melody-and-lyrics-to-inform-ai-speech">Link.</a></li>
            </ul>
        </section>
        
        <section id="other">
            <h2>Other interests</h2>
            <p>In my free time, I like reading, playing videogames, playing the violin, going to concerts and going to the gym.</p>
            <p>I am also an amateur embroiderer and soon-to-be potter!</p>
            <p>I am currently learning Japanese and on my journey for a Shotokan Karate black belt (current belt: green).</p>
        </section>
        
        <section id="contact">
            <h2>Contact</h2>
            <p>Email: ariadna dot sanchez at ed dot ac dot uk</p>
            <p>LinkedIn: <a href="https://www.linkedin.com/in/ariadna-sanchez-cervera">Ariadna Sanchez</a></p>
            <p>Twitter/X: <a href="https://x.com/SCAriadna">@SCAriadna</a></p>
        </section>

    </div>

    <footer>
        <p>© 2024 Ariadna Sanchez. All rights reserved.</p>
    </footer>
</body>
</html>
